{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb810c40",
   "metadata": {},
   "source": [
    "# Homework 3 (10 points)\n",
    "This homework will make use of pandas dataframese to extract and manipulate metadata of seismic station in the Northern California Seismic Network. The learning objective are: data download from URL, dataframes with pandas, basic data manipulation. Use the tutorials shown in class and the pandas resources (https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119661fa",
   "metadata": {},
   "source": [
    "### Think like a researcher:\n",
    "\n",
    "We want to download seismic waveforms from a seismic data archive of specific earthquakes. We am not sure what sensors (seismometers) is operating at that time. The list of stations available in the seismic networkhas more than 6000, that's way too many! So we want to filter only the seismic stations that are relevant for the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286aef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address of the website to download data\n",
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f53385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from math import cos, sin, pi, sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c778abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the website into a Python dataframe\n",
    "s = requests.get(url).content\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4944b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns start_time and end_time into datetime format\n",
    "startdate = pd.to_datetime(data['start_time'], format='%Y/%m/%d,%H:%M:%S')\n",
    "data['start_time'] = startdate\n",
    "# Avoid 'OutOfBoundsDatetime' error with year 3000\n",
    "enddate = data['end_time'].str.replace('3000', '2025')\n",
    "enddate = pd.to_datetime(enddate, format='%Y/%m/%d,%H:%M:%S')\n",
    "data['end_time'] = enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8549ede",
   "metadata": {},
   "source": [
    "After discussing with my adviser, we decided than only the following channels are relevant for the work we want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd879dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['BHE', 'BHN', 'BHZ', 'BH1', 'BH2', \\\n",
    "            'EHE', 'EHN', 'EHZ', 'EH1', 'EH2', \\\n",
    "            'HHE', 'HHN', 'HHZ', 'HH1', 'HH2', \\\n",
    "            'SHE', 'SHN', 'SHZ', 'SH1', 'SH2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e95bd0",
   "metadata": {},
   "source": [
    "## Q1 (2 points)\n",
    "\n",
    "Filter the dataset to keep only the rows with the channels as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecc9729",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      station network channel location   rate           start_time  \\\n",
       "0        AAR      NC     EHZ       --  100.0  1984/01/01,00:00:00   \n",
       "1        AAR      NC     EHZ       --  100.0  1987/05/01,00:00:00   \n",
       "2        AAR      NC     SHZ       --   20.0  1994/11/28,00:00:00   \n",
       "3        AAS      NC     EHZ       --  100.0  1984/11/27,18:45:00   \n",
       "4        AAS      NC     EHZ       --  100.0  1987/05/01,00:00:00   \n",
       "...      ...     ...     ...      ...    ...                  ...   \n",
       "6134     WMP      NC     SHE       --   20.0  1995/07/02,12:00:00   \n",
       "6135     WMP      NC     SHN       --   20.0  1995/07/02,12:00:00   \n",
       "6136     WMP      NC     SHZ       --   20.0  1995/03/02,19:00:00   \n",
       "6137     WMP      NC     SHZ       --   20.0  1995/07/02,12:00:00   \n",
       "6138     WMP      NC     SHZ       10   20.0  1995/07/02,12:00:00   \n",
       "\n",
       "                 end_time  latitude  longitude  elevation  depth   dip  \\\n",
       "0     1987/05/01,00:00:00  39.27594 -121.02696      911.0    0.0 -90.0   \n",
       "1     2006/01/04,19:19:00  39.27594 -121.02696      911.0    0.0 -90.0   \n",
       "2     2006/01/04,19:19:00  39.27594 -121.02696      911.0    0.0 -90.0   \n",
       "3     1987/05/01,00:00:00  38.43014 -121.10959       31.0    0.0 -90.0   \n",
       "4     3000/01/01,00:00:00  38.43014 -121.10959       31.0    0.0 -90.0   \n",
       "...                   ...       ...        ...        ...    ...   ...   \n",
       "6134  2002/05/08,22:30:00  35.64059 -118.78570     1078.0    0.0   0.0   \n",
       "6135  2002/05/08,22:30:00  35.64059 -118.78570     1078.0    0.0   0.0   \n",
       "6136  1995/07/02,12:00:00  35.64059 -118.78570     1078.0    0.0 -90.0   \n",
       "6137  2002/05/08,22:30:00  35.64059 -118.78570     1078.0    0.0 -90.0   \n",
       "6138  1999/05/11,23:59:00  35.64059 -118.78570     1078.0    0.0 -90.0   \n",
       "\n",
       "      azimuth  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "6134     90.0  \n",
       "6135      0.0  \n",
       "6136      0.0  \n",
       "6137      0.0  \n",
       "6138      0.0  \n",
       "\n",
       "[2711 rows x 13 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data = data.loc[data.channel.isin(channels)]\n",
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5bcce",
   "metadata": {},
   "source": [
    "## Q2  (2 points)\n",
    "My earthquake catalog starts on 2007/07/01 and ends on 2009/07/01. I am only interested in stations that started recording before 2007/07/01 and ended recording after 2009/07/01. The dataframe <code>data</code> has the start time and end times defined as <code>datetime</code> objects. That means that we can filter the dataframe columns by comparing the datetime objects. To create a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2f5648",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "s1 = datetime(2007,7,1)\n",
    "s2 = datetime(2009,7,1)\n",
    "print(type(s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30615610",
   "metadata": {},
   "source": [
    "Filter the dataset to keep only stations that started recording before 2007/07/01 and ended recording after 2009/07/01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63823607",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'datetime.datetime'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5551ee0475f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m>\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "data = data.loc[(data.start_time < s1) & (data.end_time >s2)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0436861",
   "metadata": {},
   "source": [
    "The cluster of these repeating earthquakes are located at latitude = 40.09N and longitude = -122.87E. Here is a function to compute the distance from the station to the earthquakes, and to add a column distance to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8815da2",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-9-9373716ffbb5>:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data['distance'] = np.sqrt(np.power(x, 2.0) + np.power(y, 2.0))\n"
     ]
    }
   ],
   "source": [
    "# the cluster of earthquakes is centered at the following location:\n",
    "lat0 = 40.09000\n",
    "lon0 = -122.87000\n",
    "\n",
    "a = 6378.136 # radius of the Earth in km.\n",
    "e = 0.006694470 # ellipticity\n",
    "\n",
    "\n",
    "dx = (pi / 180.0) * a * cos(lat0 * pi / 180.0) / sqrt(1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0))\n",
    "dy = (3.6 * pi / 648.0) * a * (1.0 - e * e) / ((1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0)) ** 1.5)\n",
    "x = dx * (data['longitude'] - lon0)\n",
    "y = dy * (data['latitude'] - lat0)\n",
    "\n",
    "# calculate and fill in the dataframe with the new values\n",
    "data['distance'] = np.sqrt(np.power(x, 2.0) + np.power(y, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794fc6a",
   "metadata": {},
   "source": [
    "## Q3  (3 points)\n",
    "We want to keep the stations that are located less than 100 km from my repeating earthquakes. For stations farther away, the signal-to-noise ratio would be too low. Filter the dataset to keep only stations that are within 100 km from the earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8ccfee",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     station network channel location   rate          start_time  \\\n",
       "1493     GBB      NC     EHZ       --  100.0 2000-12-06 18:38:00   \n",
       "1528     GCK      NC     EHZ       --  100.0 2000-06-06 21:58:00   \n",
       "1628     GFC      NC     EHZ       --  100.0 2001-04-03 23:25:00   \n",
       "1689     GHM      NC     EHZ       --  100.0 1987-05-01 00:00:00   \n",
       "1744     GRO      NC     EHZ       --  100.0 1990-12-13 23:30:00   \n",
       "\n",
       "                end_time  latitude  longitude  elevation  depth   dip  \\\n",
       "1493 2025-01-01 00:00:00  39.80127 -122.34550      170.0    0.0 -90.0   \n",
       "1528 2025-01-01 00:00:00  39.54375 -122.43668      251.0    0.0 -90.0   \n",
       "1628 2020-03-18 22:53:00  39.32655 -122.28886       64.0    0.0 -90.0   \n",
       "1689 2025-01-01 00:00:00  39.49545 -122.93096     1456.0    0.0 -90.0   \n",
       "1744 2025-01-01 00:00:00  39.91684 -122.67117     1261.0    0.0 -90.0   \n",
       "\n",
       "      azimuth   distance  \n",
       "1493      0.0  55.029997  \n",
       "1528      0.0  71.129241  \n",
       "1628      0.0  98.346307  \n",
       "1689      0.0  66.387179  \n",
       "1744      0.0  25.657089  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station</th>\n      <th>network</th>\n      <th>channel</th>\n      <th>location</th>\n      <th>rate</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>depth</th>\n      <th>dip</th>\n      <th>azimuth</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1493</th>\n      <td>GBB</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2000-12-06 18:38:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.80127</td>\n      <td>-122.34550</td>\n      <td>170.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>55.029997</td>\n    </tr>\n    <tr>\n      <th>1528</th>\n      <td>GCK</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2000-06-06 21:58:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.54375</td>\n      <td>-122.43668</td>\n      <td>251.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>71.129241</td>\n    </tr>\n    <tr>\n      <th>1628</th>\n      <td>GFC</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2001-04-03 23:25:00</td>\n      <td>2020-03-18 22:53:00</td>\n      <td>39.32655</td>\n      <td>-122.28886</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>98.346307</td>\n    </tr>\n    <tr>\n      <th>1689</th>\n      <td>GHM</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>1987-05-01 00:00:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.49545</td>\n      <td>-122.93096</td>\n      <td>1456.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>66.387179</td>\n    </tr>\n    <tr>\n      <th>1744</th>\n      <td>GRO</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>1990-12-13 23:30:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.91684</td>\n      <td>-122.67117</td>\n      <td>1261.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>25.657089</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data = data.loc[data.distance < 100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733269f3",
   "metadata": {},
   "source": [
    "Finally, we want to group the result such that the final result looks organized like this:\n",
    "\n",
    "|station|network|location|latitude|longitude |elevation|depth|distance |channel    |start_time         |end_time           |\n",
    "|-------|-------|--------|--------|----------|---------|-----|---------|-----------|-------------------|-------------------|\n",
    "|KBS \t|NC \t|-- \t |39.91719|-123.59561|1120.0   |0.0  |64.720762|SHZ        |2002-10-17 00:00:00|2011-10-27 21:25:00|\n",
    "|KCPB \t|NC \t|-- \t |39.68631|-123.58242|1261.0   |0.0  |75.502041|HHZ,HHN,HHE|2006-10-18 00:08:00|2010-11-01 22:00:00|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e4378",
   "metadata": {},
   "source": [
    "We want one row per station, a against one row per channel. Use the pandas function <code>agg</code> to group the channels of a given station together, and srt with the earliest start date and the latest end date. Do not forget to reset the indices!\n",
    "You can use the following function to group the channels together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cffd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"\n",
    "    Concatenate channels\n",
    "    \"\"\"\n",
    "    result = '%s' % ','.join(x)\n",
    "    result = list(set(result.split(',')))\n",
    "    result = '%s' % ','.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b99603",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     station network channel location   rate          start_time  \\\n",
       "1493     GBB      NC     EHZ       --  100.0 2000-12-06 18:38:00   \n",
       "1528     GCK      NC     EHZ       --  100.0 2000-06-06 21:58:00   \n",
       "1628     GFC      NC     EHZ       --  100.0 2001-04-03 23:25:00   \n",
       "1689     GHM      NC     EHZ       --  100.0 1987-05-01 00:00:00   \n",
       "1744     GRO      NC     EHZ       --  100.0 1990-12-13 23:30:00   \n",
       "\n",
       "                end_time  latitude  longitude  elevation  depth   dip  \\\n",
       "1493 2025-01-01 00:00:00  39.80127 -122.34550      170.0    0.0 -90.0   \n",
       "1528 2025-01-01 00:00:00  39.54375 -122.43668      251.0    0.0 -90.0   \n",
       "1628 2020-03-18 22:53:00  39.32655 -122.28886       64.0    0.0 -90.0   \n",
       "1689 2025-01-01 00:00:00  39.49545 -122.93096     1456.0    0.0 -90.0   \n",
       "1744 2025-01-01 00:00:00  39.91684 -122.67117     1261.0    0.0 -90.0   \n",
       "\n",
       "      azimuth   distance  \n",
       "1493      0.0  55.029997  \n",
       "1528      0.0  71.129241  \n",
       "1628      0.0  98.346307  \n",
       "1689      0.0  66.387179  \n",
       "1744      0.0  25.657089  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station</th>\n      <th>network</th>\n      <th>channel</th>\n      <th>location</th>\n      <th>rate</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>depth</th>\n      <th>dip</th>\n      <th>azimuth</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1493</th>\n      <td>GBB</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2000-12-06 18:38:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.80127</td>\n      <td>-122.34550</td>\n      <td>170.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>55.029997</td>\n    </tr>\n    <tr>\n      <th>1528</th>\n      <td>GCK</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2000-06-06 21:58:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.54375</td>\n      <td>-122.43668</td>\n      <td>251.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>71.129241</td>\n    </tr>\n    <tr>\n      <th>1628</th>\n      <td>GFC</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>2001-04-03 23:25:00</td>\n      <td>2020-03-18 22:53:00</td>\n      <td>39.32655</td>\n      <td>-122.28886</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>98.346307</td>\n    </tr>\n    <tr>\n      <th>1689</th>\n      <td>GHM</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>1987-05-01 00:00:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.49545</td>\n      <td>-122.93096</td>\n      <td>1456.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>66.387179</td>\n    </tr>\n    <tr>\n      <th>1744</th>\n      <td>GRO</td>\n      <td>NC</td>\n      <td>EHZ</td>\n      <td>--</td>\n      <td>100.0</td>\n      <td>1990-12-13 23:30:00</td>\n      <td>2025-01-01 00:00:00</td>\n      <td>39.91684</td>\n      <td>-122.67117</td>\n      <td>1261.0</td>\n      <td>0.0</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>25.657089</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data.groupby(['station']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})\n",
    "data.reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d00ad",
   "metadata": {},
   "source": [
    "## Q4  (3 points)\n",
    "\n",
    "How many stations are left in the dataset? Can you plot them using a mapping toolbox or matplotlib? Please add  axis labels, update the fontsize to 14 points, add a title, and a legend, save the file as a PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db24acca",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data.station.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-631f5c44db62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[1;34m'ytick.labelsize'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           'font.size':14}\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Station\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'legend.fontsize': 14, \\\n",
    "          'xtick.labelsize':14, \\\n",
    "          'ytick.labelsize':14, \\\n",
    "          'font.size':14}\n",
    "plt.rcParams.update(params)\n",
    "plt.scatter(data.longitude, data.latitude, label = \"Station\")\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Station Location')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.show()\n",
    "plt.savefig('Homework3_Station_Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd054e72497fd64358f52832107e3cdfaf9f975ee2964d8f26ed128ba56fc24de73",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}